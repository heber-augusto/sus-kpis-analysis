name: Update analisys datasets
run-name: ${{ github.actor }} is updating analysis datasets 🚀
on: 
  workflow_dispatch:     
  schedule:
    - cron:  '0 10 * * *'
    
jobs:
  Update-Datasets:
    runs-on: ubuntu-latest
    steps:
      - run: echo "🎉 The job was triggered by a ${{ github.event_name }} event."
      - run: echo "🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!"
      - run: echo "🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."
      - name: Check out repository code
        uses: actions/checkout@v3
      - run: echo "💡 The ${{ github.repository }} repository has been cloned to the runner."
      - run: echo "🖥️ The workflow is now ready to test your code on the runner."
      - name: List files in the repository
        run: |
          ls ${{ github.workspace }}
      - name: 'google-auth'
        uses: 'google-github-actions/auth@v1'
        with:
          credentials_json: '${{ secrets.gcp_credentials }}'
          
      - name: Download and prepare Spark
        run: |
          echo "enviroment setup"        

          pip3 install -r ./sia/etls/requirements.txt          

          export PYTHONHASHSEED=1234
          export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
          export SPARK_HOME=./spark-3.4.1-bin-hadoop3
          export SPARK_VERSION=3.4.1
          
          sudo sh ./sia/etls/bin/setup_spark_env.sh './'

          echo "running script"
          python3 ./sia/etls/create-base-kpis.py

      - run: echo "🍏 This job's status is ${{ job.status }}." 
      - uses: gautamkrishnar/keepalive-workflow@v1 # using the workflow with default settings
