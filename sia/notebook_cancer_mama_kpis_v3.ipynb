{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNviCQI6IDqh"
      },
      "source": [
        "\n",
        "# I - Configuração do ambiente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqola1AcrdGm"
      },
      "source": [
        "## 1.1 - Montagem do drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYbxgrEQz3Sn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enmrocYf_raz",
        "outputId": "ff5f28f2-8b3e-4d3b-c916-3e7b3ba639e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnBLAcn1ZEik"
      },
      "source": [
        "## 1.2 - Escolha do ambiente e carregamento\n",
        "São disponibilizadas duas opções de execução (dependendo da credencial utilizada)\n",
        " - Leitura: disponível para analises e usuários que não possuem permissão de escrita;\n",
        " - Escrita: disponível para atualização de bases (testes de desenvolvimento ou ambiente de produção)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Fj3xNzUzZD8W",
        "outputId": "783a9c9c-4685-407f-f915-b40c014d74d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SERVICE_ACCOUNT_USER=''\n",
            "env: SERVICE_ACCOUNT_JSON=''\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shared_drive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "if os.path.isfile('/content/monitor-rosa-leitura.json'):\n",
        "    datalake_mode = 'leitura'\n",
        "    %env SERVICE_ACCOUNT_USER=acesso-leitura@monitor-rosa.iam.gserviceaccount.com\n",
        "    %env SERVICE_ACCOUNT_JSON=/content/monitor-rosa-leitura.json\n",
        "elif os.path.isfile('/content/monitor-rosa-escrita.json'):\n",
        "    datalake_mode = 'escrita'\n",
        "    %env SERVICE_ACCOUNT_USER=acesso-escrita@monitor-rosa.iam.gserviceaccount.com\n",
        "    %env SERVICE_ACCOUNT_JSON=/content/monitor-rosa-escrita.json\n",
        "else:\n",
        "    assert(os.path.isdir('/content/drive/Shareddrives/monitor-rosa-gold') == True)\n",
        "    datalake_mode = 'shared_drive'\n",
        "    %env SERVICE_ACCOUNT_USER=''\n",
        "    %env SERVICE_ACCOUNT_JSON=''\n",
        "datalake_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxl5dgNHuCsK",
        "outputId": "496d783e-61f9-473a-a186-1745990fcc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sus-kpis-analysis': No such file or directory\n",
            "Cloning into 'sus-kpis-analysis'...\n",
            "remote: Enumerating objects: 1779, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 1779 (delta 20), reused 12 (delta 12), pack-reused 1740 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1779/1779), 4.80 MiB | 11.71 MiB/s, done.\n",
            "Resolving deltas: 100% (820/820), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r sus-kpis-analysis\n",
        "!git clone https://github.com/heber-augusto/sus-kpis-analysis.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NYsSZynDK9K"
      },
      "source": [
        "## 1.3 - Instalação de libs Python, inicialização de variáveis de ambiente e configuração/instalação do Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v3Wqjxhu4Gq",
        "outputId": "5640318a-2da1-466e-87e1-66a348c954e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 1))\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 2)) (3.5.4)\n",
            "Collecting imagehash (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 3))\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting delta-spark==2.4.0 (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 4))\n",
            "  Downloading delta_spark-2.4.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 8)) (2.155.0)\n",
            "Collecting pyspark (from -r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 2))\n",
            "  Downloading pyspark-3.4.4.tar.gz (311.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from delta-spark==2.4.0->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 4)) (8.6.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 2)) (0.10.9.7)\n",
            "Collecting PyWavelets (from imagehash->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 3))\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagehash->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.27.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (1.6.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 8)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 8)) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (1.26.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.0.0->delta-spark==2.4.0->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 4)) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (2024.12.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r /content/sus-kpis-analysis/sia/etls/requirements.txt (line 5)) (0.6.1)\n",
            "Downloading delta_spark-2.4.0-py3-none-any.whl (20 kB)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.4-py2.py3-none-any.whl size=311905460 sha256=5594db732f5ccd89184d955735a278c2380ba64070eeff95ce9143ceee97e2df\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/0a/a1/2b8f5f192c7df9fdceb8e5a62873d64e46b101f980519bcf55\n",
            "Successfully built pyspark\n",
            "Installing collected packages: findspark, PyWavelets, pyspark, imagehash, delta-spark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.4\n",
            "    Uninstalling pyspark-3.5.4:\n",
            "      Successfully uninstalled pyspark-3.5.4\n",
            "Successfully installed PyWavelets-1.8.0 delta-spark-2.4.0 findspark-2.0.1 imagehash-4.3.2 pyspark-3.4.4\n",
            "env: PYTHONHASHSEED=1234\n",
            "env: JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
            "env: SPARK_HOME=/content/spark-3.4.4-bin-hadoop3\n",
            "env: SPARK_VERSION=3.4.4\n",
            "starting spark env setup \n",
            "installing and downloading packages\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "setting enviroment variables\n",
            "spark env setup completed with success\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/sus-kpis-analysis/sia/etls/requirements.txt\n",
        "\n",
        "%env PYTHONHASHSEED=1234\n",
        "%env JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
        "%env SPARK_HOME=/content/spark-3.4.4-bin-hadoop3\n",
        "%env SPARK_VERSION=3.4.4\n",
        "\n",
        "!source /content/sus-kpis-analysis/sia/etls/bin/setup_spark_env.sh '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_O3K75fMh7K"
      },
      "outputs": [],
      "source": [
        "if datalake_mode != 'shared_drive':\n",
        "    %env XDG_CONFIG_HOME=/content/datalake\n",
        "    !source /content/sus-kpis-analysis/sia/etls/bin/install-google-drive-ocamlfuse.sh\n",
        "    !source /content/sus-kpis-analysis/sia/etls/bin/mount_google_drive_v2.sh '/content/datalake' $SERVICE_ACCOUNT_USER '0ABIY-a4qrdY9Uk9PVA' 'monitor-rosa-bronze' $SERVICE_ACCOUNT_JSON '/content'\n",
        "    !source /content/sus-kpis-analysis/sia/etls/bin/mount_google_drive_v2.sh '/content/datalake' $SERVICE_ACCOUNT_USER '0ALl0owLNr53oUk9PVA' 'monitor-rosa-silver' $SERVICE_ACCOUNT_JSON '/content'\n",
        "    !source /content/sus-kpis-analysis/sia/etls/bin/mount_google_drive_v2.sh '/content/datalake' $SERVICE_ACCOUNT_USER '0AMHp9pBeLvZiUk9PVA' 'monitor-rosa-gold' $SERVICE_ACCOUNT_JSON '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT00Lo1mTJwu"
      },
      "source": [
        "## 1.4 - Inicializa variáveis de acesso ao delta lake criado no drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> O caminho do warehouse pode ser alterado em caso de testes de escritas locais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLT8gGOcekpW",
        "outputId": "94e24cd9-2e15-4777-9a52-44e54a0710c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.4.4-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "lake_prefix = \"temp-output\"\n",
        "\n",
        "if datalake_mode in ('leitura','shared_drive',):\n",
        "    warehouse_dir = f\"/content/datalake/{lake_prefix}/\"\n",
        "\n",
        "if datalake_mode == 'escrita':\n",
        "    warehouse_dir = f\"/content/datalake/\"\n",
        "\n",
        "spark_path = os.getenv('SPARK_HOME')\n",
        "spark_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzMUcNg3k8d"
      },
      "source": [
        "## 1.5 - Inclusão da pasta do repositório no python path\n",
        "\n",
        "Procedimento permite que funções e classes presentes no repositório sejam utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dOrv8t0IMZ",
        "outputId": "c9f558b7-8673-40ef-a513-6727b9cf3646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python311.zip',\n",
              " '/usr/lib/python3.11',\n",
              " '/usr/lib/python3.11/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.11/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.11/dist-packages/IPython/extensions',\n",
              " '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor',\n",
              " '/root/.ipython',\n",
              " '/content/sus-kpis-analysis']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/sus-kpis-analysis')\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptGWtMYSIXtw"
      },
      "source": [
        "## 1.6 - Importação de funções utilizadas pelo código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0LNG7YrUyRD"
      },
      "outputs": [],
      "source": [
        "from sia.etls.lib.catalog_loader import DeltaLakeDatabaseFsCreator, load_entire_catalog_fs_v2\n",
        "from sia.etls.lib.table_utilities import vacuum_tables_from_database, table_exists\n",
        "from sia.etls.lib.fs_spark_session import create_fs_spark_session\n",
        "from sia.etls.lib.bronze_files_utilities import get_pending_files_from_bronze\n",
        "from sia.etls.lib.delta_table_creators import ParquetToDelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LWOtjtk33d6"
      },
      "source": [
        "## 1.7 - Cria Sessão Spark conectada ao Delta Lake presente no Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETM5T_gkDvAP"
      },
      "outputs": [],
      "source": [
        "spark = create_fs_spark_session(\n",
        "    warehouse_dir=warehouse_dir,\n",
        "    spark_path=spark_path\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8lBJqvC4Cak"
      },
      "source": [
        "## 1.8 - Refresh do catálogo para utilizar consultas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvYjAMOAyNmj",
        "outputId": "0c6132f2-b0b7-4f90-9791-f962a8eb97a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sia_bronze.db', 'cnes_bronze.db', 'sih_bronze.db', 'sim_bronze.db']\n",
            "Banco de dados sia_bronze criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-bronze/databases e database sia_bronze\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/\n",
            "table_list: ['ar', 'aq', 'pa', 'bi', 'am']\n",
            "Tabela ar criada\n",
            "Tabela ar criada com comando CREATE TABLE IF NOT EXISTS sia_bronze.ar USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/ar'\n",
            "Tabela aq criada\n",
            "Tabela aq criada com comando CREATE TABLE IF NOT EXISTS sia_bronze.aq USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/aq'\n",
            "Tabela pa criada\n",
            "Tabela pa criada com comando CREATE TABLE IF NOT EXISTS sia_bronze.pa USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/pa'\n",
            "Tabela bi criada\n",
            "Tabela bi criada com comando CREATE TABLE IF NOT EXISTS sia_bronze.bi USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/bi'\n",
            "Tabela am criada\n",
            "Tabela am criada com comando CREATE TABLE IF NOT EXISTS sia_bronze.am USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sia_bronze.db/am'\n",
            "Recriação das tabelas concluída.\n",
            "Banco de dados cnes_bronze criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-bronze/databases e database cnes_bronze\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/\n",
            "table_list: ['dc', 'lt', 'ep', 'pf', 'eq', 'hb', 'in', 'rc', 'sr']\n",
            "Tabela dc criada\n",
            "Tabela dc criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.dc USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/dc'\n",
            "Tabela lt criada\n",
            "Tabela lt criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.lt USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/lt'\n",
            "Tabela ep criada\n",
            "Tabela ep criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.ep USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/ep'\n",
            "Tabela pf criada\n",
            "Tabela pf criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.pf USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/pf'\n",
            "Tabela eq criada\n",
            "Tabela eq criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.eq USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/eq'\n",
            "Tabela hb criada\n",
            "Tabela hb criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.hb USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/hb'\n",
            "Tabela in criada\n",
            "Tabela in criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.in USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/in'\n",
            "Tabela rc criada\n",
            "Tabela rc criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.rc USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/rc'\n",
            "Tabela sr criada\n",
            "Tabela sr criada com comando CREATE TABLE IF NOT EXISTS cnes_bronze.sr USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/cnes_bronze.db/sr'\n",
            "Recriação das tabelas concluída.\n",
            "Banco de dados sih_bronze criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-bronze/databases e database sih_bronze\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-bronze/databases/sih_bronze.db/\n",
            "table_list: ['rd']\n",
            "Tabela rd criada\n",
            "Tabela rd criada com comando CREATE TABLE IF NOT EXISTS sih_bronze.rd USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sih_bronze.db/rd'\n",
            "Recriação das tabelas concluída.\n",
            "Banco de dados sim_bronze criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-bronze/databases e database sim_bronze\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-bronze/databases/sim_bronze.db/\n",
            "table_list: ['dores']\n",
            "Tabela dores criada\n",
            "Tabela dores criada com comando CREATE TABLE IF NOT EXISTS sim_bronze.dores USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-bronze/databases/sim_bronze.db/dores'\n",
            "Recriação das tabelas concluída.\n",
            "['cancer_data.db', 'ibge_silver.db']\n",
            "Banco de dados cancer_data criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-silver/databases e database cancer_data\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/\n",
            "table_list: ['aq_filtered', 'ar_filtered', 'dados_estados_mensal', 'dados_municipios_mensal', 'pacientes', 'procedimentos', 'procedimentos_e_pacientes', 'demografia_municipios', 'cadastro_municipios']\n",
            "Tabela aq_filtered criada\n",
            "Tabela aq_filtered criada com comando CREATE TABLE IF NOT EXISTS cancer_data.aq_filtered USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/aq_filtered'\n",
            "Tabela ar_filtered criada\n",
            "Tabela ar_filtered criada com comando CREATE TABLE IF NOT EXISTS cancer_data.ar_filtered USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/ar_filtered'\n",
            "Tabela dados_estados_mensal criada\n",
            "Tabela dados_estados_mensal criada com comando CREATE TABLE IF NOT EXISTS cancer_data.dados_estados_mensal USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/dados_estados_mensal'\n",
            "Tabela dados_municipios_mensal criada\n",
            "Tabela dados_municipios_mensal criada com comando CREATE TABLE IF NOT EXISTS cancer_data.dados_municipios_mensal USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/dados_municipios_mensal'\n",
            "Tabela pacientes criada\n",
            "Tabela pacientes criada com comando CREATE TABLE IF NOT EXISTS cancer_data.pacientes USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/pacientes'\n",
            "Tabela procedimentos criada\n",
            "Tabela procedimentos criada com comando CREATE TABLE IF NOT EXISTS cancer_data.procedimentos USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/procedimentos'\n",
            "Tabela procedimentos_e_pacientes criada\n",
            "Tabela procedimentos_e_pacientes criada com comando CREATE TABLE IF NOT EXISTS cancer_data.procedimentos_e_pacientes USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/procedimentos_e_pacientes'\n",
            "Tabela demografia_municipios criada\n",
            "Tabela demografia_municipios criada com comando CREATE TABLE IF NOT EXISTS cancer_data.demografia_municipios USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/demografia_municipios'\n",
            "Tabela cadastro_municipios criada\n",
            "Tabela cadastro_municipios criada com comando CREATE TABLE IF NOT EXISTS cancer_data.cadastro_municipios USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/cancer_data.db/cadastro_municipios'\n",
            "Recriação das tabelas concluída.\n",
            "Banco de dados ibge_silver criado.\n",
            "listando conteúdos do caminho /content/drive/Shareddrives/monitor-rosa-silver/databases e database ibge_silver\n",
            "prefix: /content/drive/Shareddrives/monitor-rosa-silver/databases/ibge_silver.db/\n",
            "table_list: ['cadastro_municipios', 'demografia_municipios']\n",
            "Tabela cadastro_municipios criada\n",
            "Tabela cadastro_municipios criada com comando CREATE TABLE IF NOT EXISTS ibge_silver.cadastro_municipios USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/ibge_silver.db/cadastro_municipios'\n",
            "Tabela demografia_municipios criada\n",
            "Tabela demografia_municipios criada com comando CREATE TABLE IF NOT EXISTS ibge_silver.demografia_municipios USING delta LOCATION '/content/drive/Shareddrives/monitor-rosa-silver/databases/ibge_silver.db/demografia_municipios'\n",
            "Recriação das tabelas concluída.\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "zone_names = ['monitor-rosa-bronze','monitor-rosa-silver','monitor-rosa-gold']\n",
        "\n",
        "if datalake_mode in ('leitura', 'escrita'):\n",
        "\n",
        "    zone_paths = [f'/content/datalake/{zone_name}/databases' for zone_name in zone_names]\n",
        "else:\n",
        "    zone_paths = [f'/content/drive/Shareddrives/{zone_name}/databases' for zone_name in zone_names]\n",
        "\n",
        "\n",
        "\n",
        "# Carrega catalogo de banco de dados, na zona bronze\n",
        "database_filter = None #['cnes_bronze.db',]\n",
        "\n",
        "table_filter = None #['sia_bronze.ar','sia_bronze.aq', 'ibge_silver.cadastro_municipios', 'ibge_silver.demografia_municipios' ]\n",
        "\n",
        "for databases_path in zone_paths:\n",
        "    load_entire_catalog_fs_v2(\n",
        "        spark_session = spark,\n",
        "        databases_path = databases_path,\n",
        "        use_db_folder_path=(datalake_mode == 'escrita'),\n",
        "        database_filter=database_filter,\n",
        "        table_filter=table_filter\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaP8BGb8HTqL"
      },
      "source": [
        "## 1.9 - Cria banco de dados gold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H641SkVm6iQk",
        "outputId": "fd179d42-9b4f-471c-f866-4ac25df102c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banco de dados cancer_mama_1 criado.\n"
          ]
        }
      ],
      "source": [
        "destination_database_name = 'cancer_mama_1'\n",
        "\n",
        "warehouse_dir_g =  f\"/content/datalake/{lake_prefix}/\"\n",
        "\n",
        "\n",
        "db_creator = DeltaLakeDatabaseFsCreator(\n",
        "    spark_session= spark,\n",
        "    database_location=warehouse_dir_g,\n",
        "    database_name=destination_database_name\n",
        ")\n",
        "db_creator.create_database(\n",
        "     use_db_folder_path=(datalake_mode == 'escrita')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeQru0rTIfct"
      },
      "source": [
        "# II - Exemplo de como listar bancos e tabelas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJybgzFHU5as",
        "outputId": "3ff39560-e19f-4a27-bad7-3a03facfed4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|    namespace|\n",
            "+-------------+\n",
            "|  cancer_data|\n",
            "|cancer_mama_1|\n",
            "|  cnes_bronze|\n",
            "|      default|\n",
            "|  ibge_silver|\n",
            "|   sia_bronze|\n",
            "|   sih_bronze|\n",
            "|   sim_bronze|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "databases = spark.sql(f\"SHOW DATABASES;\")\n",
        "databases.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYbmd2NNH3iZ",
        "outputId": "348114e1-426a-47ac-93b5-c81defcb7463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------------+-----------+\n",
            "|namespace  |tableName                |isTemporary|\n",
            "+-----------+-------------------------+-----------+\n",
            "|cancer_data|aq_filtered              |false      |\n",
            "|cancer_data|ar_filtered              |false      |\n",
            "|cancer_data|cadastro_municipios      |false      |\n",
            "|cancer_data|dados_estados_mensal     |false      |\n",
            "|cancer_data|dados_municipios_mensal  |false      |\n",
            "|cancer_data|demografia_municipios    |false      |\n",
            "|cancer_data|pacientes                |false      |\n",
            "|cancer_data|procedimentos            |false      |\n",
            "|cancer_data|procedimentos_e_pacientes|false      |\n",
            "+-----------+-------------------------+-----------+\n",
            "\n",
            "+---------+---------+-----------+\n",
            "|namespace|tableName|isTemporary|\n",
            "+---------+---------+-----------+\n",
            "+---------+---------+-----------+\n",
            "\n",
            "+-----------+---------+-----------+\n",
            "|namespace  |tableName|isTemporary|\n",
            "+-----------+---------+-----------+\n",
            "|cnes_bronze|dc       |false      |\n",
            "|cnes_bronze|ep       |false      |\n",
            "|cnes_bronze|eq       |false      |\n",
            "|cnes_bronze|hb       |false      |\n",
            "|cnes_bronze|in       |false      |\n",
            "|cnes_bronze|lt       |false      |\n",
            "|cnes_bronze|pf       |false      |\n",
            "|cnes_bronze|rc       |false      |\n",
            "|cnes_bronze|sr       |false      |\n",
            "+-----------+---------+-----------+\n",
            "\n",
            "+---------+---------+-----------+\n",
            "|namespace|tableName|isTemporary|\n",
            "+---------+---------+-----------+\n",
            "+---------+---------+-----------+\n",
            "\n",
            "+-----------+---------------------+-----------+\n",
            "|namespace  |tableName            |isTemporary|\n",
            "+-----------+---------------------+-----------+\n",
            "|ibge_silver|cadastro_municipios  |false      |\n",
            "|ibge_silver|demografia_municipios|false      |\n",
            "+-----------+---------------------+-----------+\n",
            "\n",
            "+----------+---------+-----------+\n",
            "|namespace |tableName|isTemporary|\n",
            "+----------+---------+-----------+\n",
            "|sia_bronze|am       |false      |\n",
            "|sia_bronze|aq       |false      |\n",
            "|sia_bronze|ar       |false      |\n",
            "|sia_bronze|bi       |false      |\n",
            "|sia_bronze|pa       |false      |\n",
            "+----------+---------+-----------+\n",
            "\n",
            "+----------+---------+-----------+\n",
            "|namespace |tableName|isTemporary|\n",
            "+----------+---------+-----------+\n",
            "|sih_bronze|rd       |false      |\n",
            "+----------+---------+-----------+\n",
            "\n",
            "+----------+---------+-----------+\n",
            "|namespace |tableName|isTemporary|\n",
            "+----------+---------+-----------+\n",
            "|sim_bronze|dores    |false      |\n",
            "+----------+---------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for row in databases.collect():\n",
        "    spark.sql(f\"SHOW TABLES FROM {row['namespace']};\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy88IuwDyjFQ"
      },
      "source": [
        "# III - Extração e Filtragem:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-XADxhEWvE"
      },
      "source": [
        "## 3.1 - Definindo utils, variáveis e filtros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_joP1K-LEbIQ"
      },
      "outputs": [],
      "source": [
        "def get_select_all_query(table_name, where_clause=''):\n",
        "    return f\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM {table_name}\n",
        "    {where_clause}\n",
        "    \"\"\"\n",
        "\n",
        "def run_sql_query(sql_query):\n",
        "    return spark.sql(sql_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfb1iT7fEnCh",
        "outputId": "ea27390f-706f-4795-80d0-8ac452a0f7df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('0201010569','0201010585','0201010607','0203010035','0203010043','0203020065','0203020073','0205020097','0208090037','0204030030','0204030188')\n",
            "('C500','C501','C502','C503','C504','C505','C506','C508','C509')\n"
          ]
        }
      ],
      "source": [
        "# Definindo variavel destination_database_name\n",
        "\n",
        "destination_database_name = 'cancer_mama_1'\n",
        "\n",
        "# Filtro pelo CID\n",
        "\n",
        "cid_filter = ['C500', 'C501', 'C502', 'C503', 'C504', 'C505', 'C506', 'C508', 'C509']\n",
        "\n",
        "cid_filter = f\"\"\"({','.join([f\"'{cid_id}'\" for cid_id in cid_filter])})\"\"\"\n",
        "\n",
        "proc_id_dict = {\n",
        "    '0201010569': 'BIOPSIA/EXERESE DE NÓDULO DE MAMA',\n",
        "    '0201010585': 'PUNÇÃO ASPIRATIVA DE MAMA POR AGULHA FINA',\n",
        "    '0201010607': 'PUNÇÃO DE MAMA POR AGULHA GROSSA',\n",
        "    '0203010035': 'EXAME DE CITOLOGIA (EXCETO CERVICO-VAGINAL E DE MAMA)',\n",
        "    '0203010043': 'EXAME CITOPATOLOGICO DE MAMA',\n",
        "    '0203020065': 'EXAME ANATOMOPATOLOGICO DE MAMA - BIOPSIA',\n",
        "    '0203020073': 'EXAME ANATOMOPATOLOGICO DE MAMA - PECA CIRURGICA',\n",
        "    '0205020097': 'ULTRASSONOGRAFIA MAMARIA BILATERAL',\n",
        "    '0208090037': 'CINTILOGRAFIA DE MAMA (BILATERAL)',\n",
        "    '0204030030': 'MAMOGRAFIA',\n",
        "    '0204030188': 'MAMOGRAFIA BILATERAL PARA RASTREAMENTO'\n",
        "}\n",
        "\n",
        "proc_id_filter = f\"\"\"({','.join([f\"'{proc_id}'\" for proc_id in proc_id_dict.keys()])})\"\"\"\n",
        "\n",
        "print(proc_id_filter)\n",
        "print(cid_filter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-9lMS3vug83"
      },
      "source": [
        "## 3.2 - Carrega Tabela de Cadastro de Municípios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_zDu3JoujjE"
      },
      "outputs": [],
      "source": [
        "query_cadastro_municipios = spark.sql(\"\"\"\n",
        "\n",
        "SELECT *\n",
        "FROM\n",
        "ibge_silver.cadastro_municipios\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIwwmsSHTzv"
      },
      "source": [
        "## 3.2 - Carrega tabela SIA.AR filtrando dados de câncer de mama e procedimentos de interesse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GoyzZRm7NUw"
      },
      "outputs": [],
      "source": [
        "sql_query_ar = get_select_all_query(\n",
        "    table_name='sia_bronze.ar',\n",
        "    where_clause=f\"\"\"\n",
        "        WHERE AP_CIDPRI IN {cid_filter}\n",
        "        \"\"\"\n",
        ")\n",
        "\n",
        "cancer_ar_filtered = run_sql_query(sql_query_ar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLCBiUZQ2R2t"
      },
      "outputs": [],
      "source": [
        "cancer_ar_filtered\\\n",
        "      .repartition(1)\\\n",
        "      .write\\\n",
        "      .format(\"delta\")\\\n",
        "      .mode(\"overwrite\")\\\n",
        "      .saveAsTable(f\"{destination_database_name}.ar_filtered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjhvBzKogaT9"
      },
      "source": [
        "## 3.3 - Carrega tabela SIA.AQ filtrando dados de câncer de mama e procedimentos de interesse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bIQolpgc_a9"
      },
      "outputs": [],
      "source": [
        "sql_query_aq = get_select_all_query(\n",
        "    table_name='sia_bronze.aq',\n",
        "    where_clause=f\"\"\"\n",
        "        WHERE AP_CIDPRI IN {cid_filter}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "cancer_aq_filtered = run_sql_query(sql_query_aq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Jga0Lpeq32"
      },
      "outputs": [],
      "source": [
        "cancer_aq_filtered\\\n",
        "      .repartition(1)\\\n",
        "      .write\\\n",
        "      .format(\"delta\")\\\n",
        "      .mode(\"overwrite\")\\\n",
        "      .saveAsTable(f\"{destination_database_name}.aq_filtered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ncymjIK6NlR"
      },
      "source": [
        "# IV - Processamento dos Dados dos Pacientes e Procedimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn0xcaY-j3E2"
      },
      "source": [
        "## 4.1 - Cria dados consolidados de pacientes e procedimentos (quimio e radioterapia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mx39mQ5w4S6"
      },
      "source": [
        "Radioterapia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozvlA8On_dHJ",
        "outputId": "cd93ae99-3352-4e1b-94cb-8afe3a520448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---------------+------------+------+-----+---------+\n",
            "|  data|       paciente|estadiamento| custo|obito|municipio|\n",
            "+------+---------------+------------+------+-----+---------+\n",
            "|202404|{|{~}{~~|           0|5904.0|    0|   354100|\n",
            "|202405|{{{~|~||           4|5904.0|    0|   351620|\n",
            "|202404|{|{~}|           3|5904.0|    0|   355030|\n",
            "+------+---------------+------------+------+-----+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cancer_ar_res = spark.sql(f\"\"\"\n",
        "SELECT\n",
        "    AP_CMP as data,\n",
        "    AP_CNSPCN as paciente,\n",
        "    AR_ESTADI as estadiamento,\n",
        "    DOUBLE(AP_VL_AP)  as custo,\n",
        "    INT(AP_OBITO) as obito,\n",
        "    AP_MUNPCN as municipio\n",
        "FROM {destination_database_name}.ar_filtered\n",
        "\"\"\")\n",
        "cancer_ar_res.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlF0pvjRw74j"
      },
      "source": [
        "Quimio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dyzqz4rGhmG",
        "outputId": "602d53db-eca6-4f55-b8fe-5fa101a25311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---------------+------------+------+-----+---------+\n",
            "|  data|       paciente|estadiamento| custo|obito|municipio|\n",
            "+------+---------------+------------+------+-----+---------+\n",
            "|202405|{{{{}|{}|           3| 79.75|    0|   351750|\n",
            "|202405|{}|{||           3|1400.0|    0|   355030|\n",
            "|202405|{|{}|{|           1| 79.75|    0|   355030|\n",
            "+------+---------------+------------+------+-----+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cancer_aq_res = spark.sql(f\"\"\"\n",
        "SELECT\n",
        "    AP_CMP as data,\n",
        "    AP_CNSPCN as paciente,\n",
        "    AQ_ESTADI as estadiamento,\n",
        "    DOUBLE(AP_VL_AP)  as custo,\n",
        "    INT(AP_OBITO) as obito,\n",
        "    AP_MUNPCN as municipio\n",
        "FROM {destination_database_name}.aq_filtered\n",
        "\"\"\")\n",
        "cancer_aq_res.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgAevcCNa07"
      },
      "source": [
        "## 4.2 - Unifica os dados de radio e quimio consolidados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94M3aPpRNZeT"
      },
      "outputs": [],
      "source": [
        "df_union = cancer_aq_res.union(cancer_ar_res)\n",
        "\n",
        "df_union.createOrReplaceTempView(\"cancer_ordered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYZcjpFJVtbT"
      },
      "outputs": [],
      "source": [
        "df_union\\\n",
        "  .repartition(1)\\\n",
        "  .write\\\n",
        "  .format(\"delta\")\\\n",
        "  .mode(\"overwrite\")\\\n",
        "  .saveAsTable(f\"{destination_database_name}.procedimentos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s588c0EgN5pU"
      },
      "source": [
        "## 4.3 - Consolidando os dados por paciente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kymNuaRsg87T"
      },
      "outputs": [],
      "source": [
        "res_consolidado = spark.sql(\"\"\"\n",
        "SELECT\n",
        "    paciente,\n",
        "    FIRST(data) as data_primeiro_estadiamento,\n",
        "    LAST(data) as data_ultimo_estadiamento,\n",
        "    COUNT(1) as numero_procedimentos,\n",
        "    FIRST(estadiamento) as primeiro_estadiamento,\n",
        "    LAST(estadiamento) as ultimo_estadiamento,\n",
        "    MAX (estadiamento) as maior_estadiamento,\n",
        "    MIN (estadiamento) as menor_estadiamento,\n",
        "    SUM(custo) as custo_total,\n",
        "    MAX(obito) as indicacao_obito,\n",
        "    FIRST(municipio) as primeiro_municipio,\n",
        "    LAST(municipio) as ultimo_municipio\n",
        "FROM (SELECT * FROM cancer_ordered ORDER BY paciente, data)\n",
        "GROUP BY paciente\n",
        "\"\"\")\n",
        "\n",
        "res_consolidado\\\n",
        "  .repartition(1)\\\n",
        "  .write\\\n",
        "  .format(\"delta\")\\\n",
        "  .mode(\"overwrite\")\\\n",
        "  .saveAsTable(f\"{destination_database_name}.pacientes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31EFS5RgWrPr"
      },
      "source": [
        "## 4.4 - Procedimentos e Pacientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2319Trei2iY"
      },
      "outputs": [],
      "source": [
        "procedimentos_e_pacientes = spark.sql(f\"\"\"\n",
        "  SELECT\n",
        "      c.*,\n",
        "      p.data_primeiro_estadiamento,\n",
        "      p.data_ultimo_estadiamento,\n",
        "      p.primeiro_estadiamento,\n",
        "      p.maior_estadiamento,\n",
        "      p.ultimo_estadiamento,\n",
        "      p.custo_total,\n",
        "      p.primeiro_municipio,\n",
        "      p.ultimo_municipio,\n",
        "      p.indicacao_obito\n",
        "  FROM {destination_database_name}.procedimentos AS c\n",
        "  FULL OUTER JOIN {destination_database_name}.pacientes AS p\n",
        "  ON c.paciente = p.paciente\n",
        "\"\"\")\n",
        "\n",
        "procedimentos_e_pacientes\\\n",
        "  .repartition(1)\\\n",
        "  .write\\\n",
        "  .format(\"delta\")\\\n",
        "  .mode(\"overwrite\")\\\n",
        "  .saveAsTable(f\"{destination_database_name}.procedimentos_e_pacientes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQsyVaMTTGml",
        "outputId": "83943c0a-edcb-44cc-9539-e17ac727db73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+------------+-----+-----+---------+--------------------------+------------------------+---------------------+------------------+-------------------+-----------+------------------+----------------+---------------+\n",
            "|  data|paciente|estadiamento|custo|obito|municipio|data_primeiro_estadiamento|data_ultimo_estadiamento|primeiro_estadiamento|maior_estadiamento|ultimo_estadiamento|custo_total|primeiro_municipio|ultimo_municipio|indicacao_obito|\n",
            "+------+--------+------------+-----+-----+---------+--------------------------+------------------------+---------------------+------------------+-------------------+-----------+------------------+----------------+---------------+\n",
            "|202405|        |           1|79.75|    0|   354890|                    202405|                  202405|                    1|                 4|                  3|   75437.05|            354890|          220770|              0|\n",
            "|202405|        |           2|79.75|    0|   354890|                    202405|                  202405|                    1|                 4|                  3|   75437.05|            354890|          220770|              0|\n",
            "|202405|        |           2|79.75|    0|   354890|                    202405|                  202405|                    1|                 4|                  3|   75437.05|            354890|          220770|              0|\n",
            "+------+--------+------------+-----+-----+---------+--------------------------+------------------------+---------------------+------------------+-------------------+-----------+------------------+----------------+---------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "procedimentos_e_pacientes.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZyJAon8CaMw"
      },
      "source": [
        "# V - Agregação por Município e Estado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRM6BlAT9xPY"
      },
      "source": [
        "## 5.1 - Consolida dados por municipio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60A9MQRpaCZk"
      },
      "outputs": [],
      "source": [
        "diagnosticos_por_estadiamento_municipio_df = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        primeiro_estadiamento,\n",
        "        data_primeiro_estadiamento AS data,\n",
        "        primeiro_municipio AS municipio,\n",
        "        COUNT(DISTINCT(paciente)) AS numero_diagnosticos\n",
        "    FROM {destination_database_name}.pacientes\n",
        "    WHERE primeiro_estadiamento != ''\n",
        "    GROUP BY primeiro_estadiamento, data_primeiro_estadiamento, primeiro_municipio\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "diagnosticos_por_estadiamento_municipio_df.createOrReplaceTempView(\"diagnosticos_por_estadiamento_municipio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZFX_cNdwPt"
      },
      "source": [
        "## 5.2 - Consolida dados mensais por municipio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLwtdxLCdrTN"
      },
      "outputs": [],
      "source": [
        "dados_estad_municipio_mensal_df = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        data,\n",
        "        municipio,\n",
        "        primeiro_estadiamento,\n",
        "        SUM(custo) AS custo_estadiamento,\n",
        "        COUNT(DISTINCT(paciente)) AS numero_pacientes,\n",
        "        SUM(DISTINCT(obito)) AS obitos,\n",
        "        SUM(DISTINCT(indicacao_obito)) AS obito_futuro,\n",
        "        COUNT(1) AS numero_procedimentos\n",
        "    FROM\n",
        "        (SELECT * FROM {destination_database_name}.procedimentos_e_pacientes ORDER BY data)\n",
        "    GROUP BY data, municipio, primeiro_estadiamento\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "dados_estad_municipio_mensal_df.createOrReplaceTempView(\"dados_municipios_mensal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS4PmtP9dFfD"
      },
      "source": [
        "## 5.3 - Consolida dados por municipio mensal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQBFWXwT9ts3"
      },
      "outputs": [],
      "source": [
        "dados_estad_municipio_mensal = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        mm.*,\n",
        "        COALESCE(em.numero_diagnosticos, 0) AS numero_diagnosticos\n",
        "    FROM dados_municipios_mensal mm\n",
        "    FULL OUTER JOIN diagnosticos_por_estadiamento_municipio em\n",
        "    ON mm.data = em.data\n",
        "    AND mm.municipio = em.municipio\n",
        "    AND mm.primeiro_estadiamento = em.primeiro_estadiamento\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "dados_estad_municipio_mensal\\\n",
        "    .repartition(1)\\\n",
        "    .write\\\n",
        "    .format(\"delta\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .saveAsTable(f\"{destination_database_name}.dados_estad_municipio_mensal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z0tYQaderL1"
      },
      "source": [
        "## 5.4 - Agregação por estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Ddz0QveqKk"
      },
      "outputs": [],
      "source": [
        "dados_estad_mensal = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        estado,\n",
        "        data,\n",
        "        primeiro_estadiamento,\n",
        "        SUM(custo_estadiamento) AS custo_estadiamento,\n",
        "        SUM(numero_pacientes) AS numero_pacientes,\n",
        "        COUNT(DISTINCT(municipio)) AS numero_municipios,\n",
        "        SUM(obitos) AS obitos,\n",
        "        SUM(obito_futuro) AS obitos_futuros,\n",
        "        SUM(numero_procedimentos) AS numero_procedimentos,\n",
        "        SUM(numero_diagnosticos) AS numero_diagnosticos\n",
        "    FROM (\n",
        "        SELECT\n",
        "            cadastro_cidades.nome_uf AS estado,\n",
        "            mm.*\n",
        "        FROM cancer_data.dados_municipios_mensal mm\n",
        "        LEFT JOIN cancer_data.cadastro_municipios AS cadastro_cidades\n",
        "        ON int(mm.municipio) = int(cadastro_cidades.id / 10)\n",
        "        ORDER BY data\n",
        "    ) AS dados_estado\n",
        "    GROUP BY estado, data, primeiro_estadiamento\n",
        "\"\"\")\n",
        "\n",
        "dados_estad_mensal\\\n",
        "    .repartition(1)\\\n",
        "    .write\\\n",
        "    .format(\"delta\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .saveAsTable(f\"{destination_database_name}.dados_estados_mensal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7YEI93j-zbA"
      },
      "source": [
        "# VI - Limpeza das tabelas delta, considerando 24 horas de retenção\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rafFyT9G-cFg",
        "outputId": "92df4b3b-8b2e-4b15-e2cb-ffddaa31adab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vacuum completed for table cancer_mama_1.aq_filtered\n",
            "vacuum completed for table cancer_mama_1.ar_filtered\n",
            "vacuum completed for table cancer_mama_1.dados_estad_municipio_mensal\n",
            "vacuum completed for table cancer_mama_1.dados_estados_mensal\n",
            "vacuum completed for table cancer_mama_1.pacientes\n",
            "vacuum completed for table cancer_mama_1.procedimentos\n",
            "vacuum completed for table cancer_mama_1.procedimentos_e_pacientes\n",
            "error during vacuum for table cancer_mama_1.cancer_ordered\n",
            "error during vacuum for table cancer_mama_1.dados_municipios_mensal\n",
            "error during vacuum for table cancer_mama_1.diagnosticos_por_estadiamento_municipio\n"
          ]
        }
      ],
      "source": [
        "vacuum_tables_from_database(\n",
        "        spark_session = spark,\n",
        "        database_name = destination_database_name,\n",
        "        retention_hours = 24\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eNviCQI6IDqh",
        "PeQru0rTIfct",
        "Jy88IuwDyjFQ",
        "9ncymjIK6NlR",
        "31EFS5RgWrPr",
        "4ZyJAon8CaMw",
        "kRM6BlAT9xPY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}